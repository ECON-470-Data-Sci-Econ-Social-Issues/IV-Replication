{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convert ipynb to HTML in Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Instruction**:    \n",
        "1. Download the ipynb, which you want to convert, on your local computer.    \n",
        "2. Run the code below to upload the ipynb.  \n",
        "3. The html version will be downloaded automatically on your local machine.\n",
        "\n",
        "Enjoy it!"
      ],
      "metadata": {
        "id": "OOUwSOZ4AqyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4FhcP565-JpA"
      },
      "outputs": [],
      "source": [
        "#@title Convert ipynb to HTML in Colab\n",
        "# Upload ipynb\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "# Convert ipynb to html\n",
        "import subprocess\n",
        "file0 = list(f.keys())[0]\n",
        "_ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n",
        "_ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n",
        "\n",
        "# download the html\n",
        "files.download(file0[:-5]+\"html\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# pd.read_stata('convstate.dta').to_csv(\"csv_files/convstate.csv\", index = False)\n",
        "\n",
        "# pd.read_stata('countytodma.dta').to_csv(\"csv_files/countytodma.csv\", index = False)\n",
        "\n",
        "#pd.read_stata('ctyunemrate.dta').to_csv(\"csv_files/ctyunemrate.csv\", index = False\n",
        "# print(\"ctyunemrate.dta:\")\n",
        "# print(pd.read_stata('ctyunemrate.dta'))\n",
        "\n",
        "#pd.read_stata('dmacode.dta').to_csv(\"csv_files/dmacode.csv\", index = False)\n",
        "\n",
        "# print(\"dma_characteristics.dta:\")\n",
        "# print(pd.read_stata('dma_characteristics.dta'))\n",
        "\n",
        "# print(\"dmacode.dta:\")\n",
        "# print(pd.read_stata('dmacode.dta'))\n",
        "#pd.read_stata('googletrends-state-raw.dta').to_csv(\"csv_files/googletrends-state-raw.csv\", index = False)\n",
        "\n",
        "# print(\"googletrends-state-raw.dta:\")\n",
        "# print(pd.read_stata('googletrends-state-raw.dta'))\n",
        "#pd.read_stata('googletrends-state.dta').to_csv(\"csv_files/googletrends-state.csv\", index = False)\n",
        "\n",
        "# print(\"googletrends-state.dta:\")\n",
        "# print(pd.read_stata('googletrends-state.dta'))\n",
        "#pd.read_stata('googletrends-state2.dta').to_csv(\"csv_files/googletrends-state2.csv\", index = False)\n",
        "\n",
        "# print(\"googletrends-state2.dta:\")\n",
        "# print(pd.read_stata('googletrends-state2.dta'))\n",
        "pd.read_stata('googletrends-thehills.dta').to_csv(\"csv_files/googletrends-thehills.csv\", index = False)\n",
        "\n",
        "# print(\"googletrends-thehills.dta:\")\n",
        "# print(pd.read_stata('googletrends-thehills.dta'))\n",
        "\n",
        "# print(\"graph-treatment.do:\")\n",
        "# print(pd.read_stata('graph-treatment.do'))"
      ],
      "metadata": {
        "id": "050DKoAK9WgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your main dataset\n",
        "dataset = pd.read_csv('csv_files/merged_dropped_df2_df3.csv')\n",
        "\n",
        "# Load the Twitter data\n",
        "twitter_data = pd.read_csv('csv_files/twitter.csv')\n",
        "\n",
        "\n",
        "print(dataset.columns)\n",
        "print(twitter_data.columns)\n",
        "\n",
        "\n",
        "# Example of renaming columns in the twitter_data DataFrame\n",
        "twitter_data.rename(columns={\n",
        "    'Log Tweet Rate: Birth Control': 'birth_control_tweet_rate',\n",
        "    'Log Tweet Rate: Abortion': 'abortion_tweet_rate'\n",
        "    # Add more mappings here if you have more columns\n",
        "}, inplace=True)\n",
        "\n",
        "# Rename the 'abort' column in your main dataset to match the naming convention\n",
        "dataset.rename(columns={\n",
        "    'abort': 'abortion_rate'\n",
        "    # Add any other column renames here\n",
        "}, inplace=True)\n",
        "# Convert to string if these are categorical or identifier variables\n",
        "dataset['abortion_rate'] = dataset['abortion_rate'].astype(str)\n",
        "twitter_data['abortion_tweet_rate'] = twitter_data['abortion_tweet_rate'].astype(str)\n",
        "# Merging datasets on a common column, e.g., 'date'\n",
        "merged_dataset = pd.merge(dataset, twitter_data, left_on='abortion_rate', right_on='abortion_tweet_rate', how='left')\n",
        "\n",
        "print(merged_dataset.head())"
      ],
      "metadata": {
        "id": "7Z-jY9en95-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "df1 = pd.read_csv('csv_files/googletrends-state-raw.csv')\n",
        "df2 = pd.read_csv('csv_files/googletrends-state.csv')\n",
        "df3 = pd.read_csv('csv_files/googletrends-state2.csv')\n",
        "\n",
        "# Since df2 and df3 share year column\n",
        "merged_df2_df3 = pd.merge(df2, df3, on= [\"stname\", \"year\", \"fempop1519\", \"hgabort\", \"hgpill\", \"sexft\", \"virgin\", \"sexhurt\", \"hgbc\", \"index16p\", \"abort\", \"bc\"], how=\"inner\")\n",
        "merged_df2_df3.to_csv(\"csv_files/merged_df2_df3.csv\", index=\"False\")\n"
      ],
      "metadata": {
        "id": "tJPuJF28-IS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "df1 = pd.read_csv('csv_files/googletrends-state-raw.csv')\n",
        "df2 = pd.read_csv('csv_files/googletrends-state.csv')\n",
        "df3 = pd.read_csv('csv_files/googletrends-state2.csv')\n",
        "\n",
        "# Since df2 and df3 share year column\n",
        "merged_df2_df3 = pd.merge(df2, df3, on= [\"stname\", \"year\", \"fempop1519\", \"hgabort\", \"hgpill\", \"sexft\", \"virgin\", \"sexhurt\", \"hgbc\", \"index16p\", \"abort\", \"bc\"], how=\"inner\")\n",
        "merged_df2_df3.to_csv(\"csv_files/merged_df2_df3.csv\", index=\"False\")\n"
      ],
      "metadata": {
        "id": "R0kn0o-n-KyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('csv_files/merged_df2_df3.csv')\n",
        "\n",
        "merged_dropped_df2_df3 = df.drop(['index16p', 'stview16pTM', 'stview0809', 'strate16pTM', 'strate0809'], axis=1)\n",
        "merged_dropped_df2_df3.to_csv('csv_files/merged_dropped_df2_df3.csv', index=\"False\")"
      ],
      "metadata": {
        "id": "8fWnFyXh-MVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('csv_files/merge_datasets.csv')  # Adjust with your actual dataset path\n",
        "\n",
        "# Data Cleaning Steps\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinite values with NaN\n",
        "\n",
        "# Example: Fill NaN values for 'sexft' and 'birth control: (United States)' with the mean or median\n",
        "df['sexft'].fillna(df['sexft'].mean(), inplace=True)\n",
        "df['birth control: (United States)'].fillna(df['birth control: (United States)'].median(), inplace=True)\n",
        "df['16 and pregnant: (United States)'].fillna(df['16 and pregnant: (United States)'].mean(), inplace=True)\n",
        "\n",
        "# Continue with your analysis only if df is not empty\n",
        "if not df.empty:\n",
        "    # Define variables\n",
        "    Y = df['abort']\n",
        "    X = df[['sexft', 'birth control: (United States)']]\n",
        "    X = sm.add_constant(X)\n",
        "    Z = df['16 and pregnant: (United States)']\n",
        "\n",
        "    # Perform IV Estimation\n",
        "    iv_model = IV2SLS(Y, X, Z).fit()\n",
        "\n",
        "    # Print the summary of the IV estimation\n",
        "    print(iv_model.summary())\n",
        "else:\n",
        "    print(\"DataFrame is empty after handling missing values.\")\n",
        "\n",
        "# Assuming 'iv_model' is your IV2SLS model result\n",
        "summary = iv_model.summary().as_text()\n",
        "\n",
        "# Specify the path and filename for your results\n",
        "results_path = 'iv_results.txt'\n",
        "\n",
        "# Save the summary to a file\n",
        "with open(results_path, 'w') as f:\n",
        "    f.write(summary)"
      ],
      "metadata": {
        "id": "PNn1CCkR-QGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKwFN_dy-R0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}